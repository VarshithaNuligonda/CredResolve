This project implements a fully voice-first, agentic AI system that operates end-to-end in native Indian languages such as Telugu, Marathi, Tamil, Bengali, Hindi, and Odia to help users identify eligible government welfare schemes. The system captures user speech through the browser, converts it to text using Whisper STT in the selected non-English language, reasons and plans using a state-driven agent built with LangGraph, and responds back using native-language text-to-speech. It goes beyond a chatbot by maintaining conversation memory across turns, autonomously asking follow-up questions when critical information like age or income is missing, and handling speech recognition failures with retries and fallbacks. The agent explicitly uses multiple tools, including an eligibility evaluation engine and a scheme information tool, to make decisions rather than relying on hard-coded responses. A planner node controls the workflow, deciding when to gather more information and when to execute tools and generate final recommendations. All reasoning and outputs are enforced in the chosen Indian language, satisfying the mandatory scenario of a voice-based public welfare service agent while demonstrating true agentic behavior, decision-making, tool usage, memory, and failure handling, and avoiding all disallowed patterns such as text-only or single-prompt solutions.
